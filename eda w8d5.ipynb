{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphlab as gl\n",
    "import re\n",
    "# pip install --upgrade \n",
    "# --no-cache-dir https://get.dato.com/GraphLab-Create/1.8.5/justin@thezecks.com\n",
    "# /9378-F674-129B-F6B9-F178-B959-E07A-3D81/GraphLab-Create-License.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "''' File 5: all of the above,\n",
    "tldr: the above table is all previous tables joined on year and quarter, household_id, and person_id\n",
    "\n",
    "The incident-level extract file is not the same as the incident record-type file. The incident-level extract file is a file created by prepending\n",
    "household and person variables to incident records using the YEARQ (YEAR AND QUARTER OF INTERVIEW), IDHH (NCVS ID FOR\n",
    "HOUSEHOLDS), and IDPER (NCVS ID FOR PERSONS) variables as match keys. For data-year formats, this file has been \"bounded\"\n",
    "to contain incidents occurring within the specific calendar year, regardless of when the interview was conducted. Under the collection-year\n",
    "format, the incident-level extract file is not \"bounded\" based on when the incidents occurred; rather, it contains incidents reported in 2012,\n",
    "regardless of when they occurred\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def codetxtIntoDict():\n",
    "\n",
    "    with open('data/data_meta/BIG-Codebook.txt') as f:\n",
    "        codebook = f.readlines()\n",
    "\n",
    "    codebook = codebook[10000:]\n",
    "\n",
    "    objs = []\n",
    "    v4_keys = []\n",
    "    v4_values = []\n",
    "    lastline = False\n",
    "    for line in codebook:\n",
    "\n",
    "        if lastline and line != \"\\n\":\n",
    "            v4_values.append(line)\n",
    "        lastLine = False    \n",
    "\n",
    "        matchObj = re.match('V4...', line, re.I)\n",
    "\n",
    "        if matchObj:\n",
    "            objs.append(matchObj)\n",
    "            v4_keys.append(line)\n",
    "            lastline = True\n",
    "\n",
    "    v4_keys = v4_keys[0:604]\n",
    "    kk = []\n",
    "    for line in v4_keys:\n",
    "        ll = line.replace(\" - \", \"-\").replace(\"\\n\", \"\")\n",
    "        #print ll\n",
    "        sp = ll.split('-')\n",
    "        kk.append(sp)\n",
    "\n",
    "    code_dict = {}\n",
    "    for line in kk:\n",
    "        code_dict[line[0]] = line[1]\n",
    "    return code_dict\n",
    "    \n",
    "code_dict = codetxtIntoDict()\n",
    "print code_dict['V4115']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_data = pd.read_table('data/5-Data.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dfall.info()\n",
    "# 9215 rows, 1145 collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def delFeatures(features):\n",
    "    for cur_feat in features:\n",
    "        del df_data[cur_feat]\n",
    "        \n",
    "        \n",
    "\n",
    "low_var_features = ['V2001', 'V2009', 'V2027', 'V2028', 'V2029', 'V2030', 'V2031', 'V2109', \n",
    "                    'V2110', 'V2112', 'V2114', 'V2115', 'V2123', 'V2131', 'V2142', 'V3001', \n",
    "                    'V3027', 'V3051', 'V3057', 'V3060', 'V3069', 'V3082', 'V4001', 'V4319', \n",
    "                    'V4320']\n",
    "\n",
    "                        #'V4528\n",
    "overpowered_features = ['V4529', 'V4112', 'V4060']\n",
    "\n",
    "'''\n",
    "V4528    TYPE OF CRIME CODE (OLD, NCS)\n",
    "V4529 - TYPE OF CRIME CODE (NEW, NCVS)\n",
    "V4112 -    INJURIES: RAPE INJURIES  \n",
    "V4060 - OFFENDER HIT OR ATTACK (ALLOCATED)\n",
    "'''\n",
    "delFeatures(low_var_features)\n",
    "delFeatures(overpowered_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doOneModel(predict, df_to_predict_on):\n",
    "    \n",
    "    sf_data = gl.SFrame(df_to_predict_on)\n",
    "    \n",
    "    if predict in code_dict.keys():\n",
    "        print (predict + \" is in the dictionary; \" + predict + \" = \" + code_dict[predict] + '\\n')\n",
    "    \n",
    "    # graphlab.boosted_trees_classifier.create(dataset, target, features=None, \n",
    "    # max_iterations=10, validation_set='auto', class_weights=None, max_depth=6, \n",
    "    # step_size=0.3, min_loss_reduction=0.0, min_child_weight=0.1, row_subsample=1.0, \n",
    "    # column_subsample=1.0, verbose=True, random_seed=None, metric='auto', **kwargs)\n",
    "    \n",
    "    model = gl.boosted_trees_classifier.create(sf_data, predict, features=None, \n",
    "            max_iterations=3, validation_set='auto', class_weights=None, max_depth=10, \n",
    "            step_size=0.3, min_loss_reduction=0.0, min_child_weight=0.1, row_subsample=1.0, \n",
    "            column_subsample=1.0, verbose=True, random_seed=42, metric='auto')\n",
    "    \n",
    "    predictions = model.predict(sf_data)\n",
    "    results = model.evaluate(sf_data)\n",
    "    print \" -> Finished computing model.\"\n",
    "    print \"\\n<------------------------------------------------------------->\"\n",
    "    print \"Results for \" + predict + \" \" + code_dict[predict] + \" :\\n\"\n",
    "    print \"<------------------------------------------------------------->\"\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printResults(model):\n",
    "    \n",
    "    print \"Feature importance: \\n\", model.get_feature_importance()\n",
    "    \n",
    "    print \"Model summary: \\n\", model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printNFeatures(N, model)\n",
    "\n",
    "    top_n_features = N\n",
    "\n",
    "    features_small = list(model.get_feature_importance()['name'][0:top_n_features])\n",
    "    print \"top \" + str(top_n_features) + \" features of model;\"\n",
    "\n",
    "    for f in features_small:   \n",
    "        print f, \" \", code_dict[f]\n",
    "        \n",
    "    predict = 'V4528'\n",
    "# 4528, type of crime\n",
    "features_small.append(predict)\n",
    "\n",
    "df_small = df_data[features_small]\n",
    "#df_small.head()\n",
    "    \n",
    "    return features_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = 'V4528'\n",
    "\n",
    "\n",
    "m_boostedT = doOneModel(predict, df_data)\n",
    "\n",
    "printResults(m_boostedT)\n",
    "topNFeatures = printNFeatures(10, m_boostedT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Multiple columns can be selected by passing a list of column names:\n",
    ">>> sf = SFrame({'id':[1,2,3],'val':['A','B','C'],'val2':[5,6,7]})\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a slice of df_data with given feature_importance and then make a model with just those features\n",
    "# 4528, type of crime\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_boosted_small = doOneModel(predict, df_small)\n",
    "printResults(m_boosted_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Things to try later:\n",
    "https://dato.com/products/create/docs/graphlab.toolkits.feature_engineering.html#categorical-features\n",
    "\n",
    "RandomProjection \tProject high-dimensional numeric features into a low-dimensional subspace.\n",
    "\n",
    "OneHotEncoder \tEncode a collection of categorical features using a 1-of-K encoding scheme.\n",
    "CountThresholder \tMap infrequent categorical variables to a new/separate category.\n",
    "CategoricalImputer \tThe purpose of this imputer is to fill missing values (None) in data sets\n",
    " that have categorical data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
